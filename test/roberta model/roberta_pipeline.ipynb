{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "from unidecode import unidecode\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from gensim.models import Word2Vec\n",
    "import contractions\n",
    "\n",
    "from transformers import BertTokenizerFast, RobertaTokenizerFast, TFRobertaModel, TFBertModel\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional,Embedding, Dropout,BatchNormalization, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from transformers import BertTokenizerFast, RobertaTokenizerFast, TFRobertaModel, TFBertModel,AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'../../data/Corona_NLP_train.csv', encoding= 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data to only conbtain the tweets and the sentiment\n",
    "data = data[['OriginalTweet', 'Sentiment']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sentiment distribution using plotly\n",
    "px.histogram(data, x='Sentiment', title='Sentiment Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data seems balanced, we can now proceed to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Column Analysis\n",
    "data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sentiments to only three categories|\n",
    "data['Sentiment'] = data['Sentiment'].map({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y\n",
    "X = data['OriginalTweet']\n",
    "y = data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformer for Preprocessing and Tokenization\n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name='roberta-base', tokenizer_type='roberta-base', max_len=128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - model_name: Hugging Face model name (e.g., 'bert-base-uncased', 'roberta-base').\n",
    "        - tokenizer_type: Tokenizer type to match the model (e.g., 'bert', 'roberta').\n",
    "        - max_len: Maximum token length for input sequences.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer_type = tokenizer_type\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = TFAutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        text = unidecode(text)  # Normalize Unicode\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "        text = re.sub(r'#', ' ', text)  # Replace hashtags with space\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "        text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "        return text\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        for i in range(len(X)):\n",
    "            preprocessed_text = self.preprocess_text(X.iloc[i])\n",
    "            encoded = self.tokenizer.encode_plus(\n",
    "                preprocessed_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_len,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True\n",
    "            )\n",
    "            input_ids.append(encoded['input_ids'])\n",
    "            attention_masks.append(encoded['attention_mask'])\n",
    "        return np.array(input_ids), np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build the model\n",
    "def build_bert_model(bert_model, max_len, num_classes):\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    attention_masks = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name='attention_masks')\n",
    "    embeddings = bert_model([input_ids, attention_masks])[1]\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(embeddings)\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks], outputs=output)\n",
    "    model.compile(tf.optimizers.Adam(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test Split and Pipeline Integration\n",
    "def create_pipeline(data, labels, model_name='roberta-base', tokenizer_type='roberta-base', max_len=128, batch_size=32, epochs=4):\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Create the transformer\n",
    "    transformer = BertTransformer(model_name=model_name, tokenizer_type=tokenizer_type, max_len=max_len)\n",
    "    \n",
    "    # Transform data\n",
    "    X_train_ids, X_train_masks = transformer.fit_transform(X_train)\n",
    "    X_test_ids, X_test_masks = transformer.transform(X_test)\n",
    "    \n",
    "    # Build the BERT model\n",
    "    bert_model = transformer.model\n",
    "    num_classes = len(np.unique(labels))\n",
    "    model = build_bert_model(bert_model, max_len, num_classes)\n",
    "    \n",
    "    # create a keras callback to stop the training if the model does not improve\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=2,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    with tf.device('/GPU:0'):\n",
    "        history = model.fit(\n",
    "            [X_train_ids, X_train_masks], y_train,\n",
    "            validation_data=([X_test_ids, X_test_masks], y_test),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stopping],\n",
    "        )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = np.argmax(model.predict([X_test_ids, X_test_masks]), axis=1)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "    return model, transformer, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth or limit memory allocation\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=4096)]  # Limit to 4GB\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, transformer, history = create_pipeline(X, y, model_name='roberta-base', tokenizer_type='roberta-base', max_len=128, batch_size=2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to evaluate the model\n",
    "def evaluate_model(model, transformer, X_test, y_test):\n",
    "    X_test_ids, X_test_masks = transformer.transform(X_test)\n",
    "    y_pred = np.argmax(model.predict([X_test_ids, X_test_masks]), axis=1)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the testing data\n",
    "test_data = pd.read_csv(r'../../data/Corona_NLP_test.csv', encoding= 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data to only conbtain the tweets and the sentiment\n",
    "test_data = test_data[['OriginalTweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into X and y\n",
    "X_test = test_data['OriginalTweet']\n",
    "y_test = test_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sentiments to only three categories|\n",
    "y_test = y_test.map({'Extremely Negative':0,'Negative':0,'Neutral':1,'Positive':2,'Extremely Positive':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, transformer, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
